{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Test Dataset Preprocessing\n",
    "\n",
    "The test data preprocessing is the same as training data preprocessing, however it should performed after the training data\n",
    "preprocessing pipeline has finished, in order to avoid data leakage and overfitting!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from py_stringmatching.similarity_measure.monge_elkan import MongeElkan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def find_k_nearest_by_coordinates(\n",
    "        samples_df: pd.DataFrame,\n",
    "        k_nearest: int,\n",
    "        longitude: float,\n",
    "        latitude: float\n",
    ") -> pd.DataFrame:\n",
    "    geo_coordinates = samples_df[['longitude', 'latitude']]\n",
    "    target_coord = np.float32([longitude, latitude])\n",
    "    distances = np.sqrt(np.sum(np.power(target_coord - geo_coordinates, 2), axis=1))\n",
    "    min_distance_indices = np.argpartition(distances, k_nearest)[1: k_nearest+1]\n",
    "    return samples_df.iloc[min_distance_indices]\n",
    "\n",
    "\n",
    "def impute_zeros_by_nearby_samples(\n",
    "        samples_df: pd.DataFrame,\n",
    "        row: pd.Series,\n",
    "        location_column: str,\n",
    "        target_column: str,\n",
    "        std_threshold: float or None\n",
    ") -> (pd.Series, bool):\n",
    "    imputed = False\n",
    "    area = row[location_column]\n",
    "    target_values = samples_df.loc[samples_df[location_column] == area, target_column]\n",
    "\n",
    "    if target_values.shape[0] > 1:\n",
    "        non_zero_ids = target_values > 0\n",
    "\n",
    "        if non_zero_ids.sum() > 0:\n",
    "            non_zero_values = target_values[non_zero_ids]\n",
    "\n",
    "            if std_threshold is not None and np.std(non_zero_values) > std_threshold:\n",
    "                return row, False\n",
    "            row[target_column] = non_zero_values.mean()\n",
    "            imputed = True\n",
    "    return row, imputed\n",
    "\n",
    "\n",
    "def compute_recorded_season_and_operation_time(samples_df: pd.DataFrame) -> (pd.DataFrame, int):\n",
    "    seasons = {\n",
    "        1: 0, 2: 0,\n",
    "        3: 1, 4: 1, 5: 1,\n",
    "        6: 2, 7: 2, 8: 2, 9: 2, 10: 2,\n",
    "        11: 3, 12: 3,\n",
    "    }\n",
    "\n",
    "    samples_df['seasons'] = pd.DataFrame({'Months': pd.DatetimeIndex(samples_df['date_recorded']).month})\n",
    "    samples_df['seasons'] = samples_df['seasons'].apply(lambda month: seasons[month])\n",
    "\n",
    "    samples_df['construction_year'] = samples_df['construction_year'].replace({0: 10000})\n",
    "    samples_df['operation_time'] = pd.DatetimeIndex(samples_df['date_recorded']).year - samples_df['construction_year']\n",
    "    samples_df.loc[samples_df['operation_time'] < 0, 'operation_time'] = -1\n",
    "    return samples_df, (samples_df['operation_time'] == -1).sum()\n",
    "\n",
    "\n",
    "def preprocess_single_token(token: str) -> str:\n",
    "    non_allowed = ['.', '/', '\\'', ',', '&', '(', ')', '-', '_', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    for ch in non_allowed:\n",
    "        token = token.replace(ch, ' ')\n",
    "    token = re.sub('\\\\s+', ' ', token).lower()\n",
    "    return token.lower()\n",
    "\n",
    "\n",
    "def cluster_similar_tokens(\n",
    "        samples_df: pd.DataFrame,\n",
    "        preprocessed_token_with_counts: pd.Series,\n",
    "        target_column: str,\n",
    "        similarity_threshold: int\n",
    ") -> (pd.DataFrame, dict, int):\n",
    "    clusters = {}\n",
    "\n",
    "    similarity_algorithm = MongeElkan()\n",
    "    num_clustered = 0\n",
    "\n",
    "    original_token_counts = samples_df[target_column].value_counts()\n",
    "    preprocess_token_list = list(preprocessed_token_with_counts.index)\n",
    "\n",
    "    for original_token, original_token_count in original_token_counts.items():\n",
    "        preprocessed_token = preprocess_single_token(token=original_token)\n",
    "\n",
    "        similarities = {\n",
    "            token2: similarity_algorithm.get_raw_score(preprocessed_token.split(' '), token2.split(' '))\n",
    "            for token2 in preprocess_token_list if preprocessed_token != token2\n",
    "        }\n",
    "\n",
    "        most_similar_token = max(similarities, key=similarities.get)\n",
    "        similarity_score = similarities[most_similar_token]\n",
    "\n",
    "        if similarity_score >= similarity_threshold and original_token_count < preprocessed_token_with_counts[most_similar_token]:\n",
    "            clusters[original_token] = most_similar_token\n",
    "            num_clustered += 1\n",
    "        else:\n",
    "            clusters[original_token] = preprocessed_token\n",
    "\n",
    "    samples_df[target_column] = samples_df[target_column].apply(lambda token: clusters[token])\n",
    "    return samples_df, num_clustered\n",
    "\n",
    "\n",
    "def impute_public_meeting_and_permit(samples_df: pd.DataFrame) -> (pd.DataFrame, int, int):\n",
    "    for target_column in ['public_meeting', 'permit']:\n",
    "        samples_df[target_column] = samples_df[target_column].fillna('Unknown')\n",
    "        samples_df[target_column] = samples_df[target_column].replace({'False': 0, 'True': 1, 'Unknown': -1})\n",
    "    return samples_df, (samples_df['public_meeting'] == -1).sum(), (samples_df['permit'] == -1).sum()\n",
    "\n",
    "\n",
    "def impute_nan_row_by_nearby_samples(\n",
    "        samples_df: pd.DataFrame,\n",
    "        row: pd.Series,\n",
    "        location_column: str,\n",
    "        target_column: str,\n",
    "        frequency_threshold: float\n",
    ") -> (pd.Series, bool):\n",
    "    imputed = False\n",
    "\n",
    "    area = row[location_column]\n",
    "    target_values = samples_df.loc[samples_df[location_column] == area, target_column]\n",
    "\n",
    "    if target_values.shape[0] > 1:\n",
    "        not_na_ids = target_values.notna()\n",
    "\n",
    "        if not_na_ids.sum() > 0:\n",
    "            value_frequencies = target_values.value_counts() / target_values.shape[0]\n",
    "            non_nan_values = target_values[not_na_ids]\n",
    "            most_frequent_value = non_nan_values.mode()\n",
    "\n",
    "            if frequency_threshold is not None and value_frequencies[most_frequent_value].tolist()[0] < frequency_threshold:\n",
    "                return row, False\n",
    "            row[target_column] = most_frequent_value\n",
    "            imputed = True\n",
    "    return row, imputed\n",
    "\n",
    "\n",
    "def impute_unknown_row_by_nearby_samples(\n",
    "        samples_df: pd.DataFrame,\n",
    "        row: pd.Series,\n",
    "        location_column: str,\n",
    "        target_column: str,\n",
    "        frequency_threshold: float\n",
    ") -> (pd.Series, bool):\n",
    "    imputed = False\n",
    "\n",
    "    area = row[location_column]\n",
    "    target_values = samples_df.loc[samples_df[location_column] == area, target_column]\n",
    "\n",
    "    if target_values.shape[0] > 1:\n",
    "        not_unknown_ids = target_values != 'unknown'\n",
    "\n",
    "        if not_unknown_ids.sum() > 0:\n",
    "            value_frequencies = target_values.value_counts() / target_values.shape[0]\n",
    "            most_frequent_value_frequency = value_frequencies.values[0]\n",
    "\n",
    "            if value_frequencies.index[0] != 'unknown' and most_frequent_value_frequency >= frequency_threshold:\n",
    "                row[target_column] = value_frequencies.index[0]\n",
    "                imputed = True\n",
    "    return row, imputed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Train-Test Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "((59400, 42), (14850, 40))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_inputs = pd.read_csv('train_inputs.csv')\n",
    "test_samples = pd.read_csv('test.csv')\n",
    "\n",
    "train_inputs.shape, test_samples.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imputing Amount TSH, Population, GPS Height"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed 1039 values of \"amount_tsh\" using nearby \"subvillage\" samples\n",
      "Imputed 306 values of \"population\" using nearby \"subvillage\" samples\n",
      "Imputed 3337 values of \"gps_height\" using nearby \"subvillage\" samples\n",
      "Imputed 1866 values of \"gps_height\" using nearby \"ward\" samples\n",
      "Imputed 8 values of \"gps_height\" using nearby \"lga\" samples\n",
      "Imputed 0 values of \"gps_height\" using nearby \"district_code\" samples\n"
     ]
    }
   ],
   "source": [
    "amount_tsh_std_threshold = 50\n",
    "population_std_threshold = 50\n",
    "\n",
    "for target_column, std_threshold in zip(['amount_tsh', 'population'], [amount_tsh_std_threshold, population_std_threshold]):\n",
    "    num_imputed = 0\n",
    "\n",
    "    zero_ids = np.where(test_samples[target_column] == 0)[0]\n",
    "    for zero_id in zero_ids:\n",
    "        row = test_samples.iloc[zero_id]\n",
    "\n",
    "        row, imputed = impute_zeros_by_nearby_samples(\n",
    "            samples_df=train_inputs,\n",
    "            row=row,\n",
    "            location_column='subvillage',\n",
    "            target_column=target_column,\n",
    "            std_threshold=std_threshold\n",
    "        )\n",
    "        test_samples.iloc[zero_id] = row\n",
    "        num_imputed += imputed\n",
    "    print(f'Imputed {num_imputed} values of \"{target_column}\" using nearby \"subvillage\" samples')\n",
    "\n",
    "for location_column in ['subvillage', 'ward', 'lga', 'district_code']:\n",
    "    num_imputed = 0\n",
    "\n",
    "    zero_ids = np.where(test_samples['gps_height'] == 0)[0]\n",
    "    for zero_id in zero_ids:\n",
    "        row = test_samples.iloc[zero_id]\n",
    "\n",
    "        row, imputed = impute_zeros_by_nearby_samples(\n",
    "            samples_df=train_inputs,\n",
    "            row=row,\n",
    "            location_column=location_column,\n",
    "            target_column='gps_height',\n",
    "            std_threshold=None\n",
    "        )\n",
    "        test_samples.iloc[zero_id] = row\n",
    "        num_imputed += imputed\n",
    "    print(f'Imputed {num_imputed} values of \"gps_height\" using nearby \"{location_column}\" samples')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Computing Recorded Season, Operation Time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'5263 invalid dates were set to -1'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples, num_invalid_operation_times = compute_recorded_season_and_operation_time(samples_df=test_samples)\n",
    "f'{num_invalid_operation_times.sum()} invalid dates were set to -1'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# # Funder & Installer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique funder = 981 before clustering\n",
      "Iteration = 1, Clustered 933 tokens\n",
      "Iteration = 2, Clustered 136 tokens\n",
      "Iteration = 3, Clustered 47 tokens\n",
      "Iteration = 4, Clustered 23 tokens\n",
      "Iteration = 5, Clustered 15 tokens\n",
      "Iteration = 6, Clustered 12 tokens\n",
      "Iteration = 7, Clustered 11 tokens\n",
      "Iteration = 8, Clustered 11 tokens\n",
      "Number of unique funder = 77 after clustering\n",
      "Number of unique installer = 1092 before clustering\n",
      "Iteration = 1, Clustered 1057 tokens\n",
      "Iteration = 2, Clustered 148 tokens\n",
      "Iteration = 3, Clustered 50 tokens\n",
      "Iteration = 4, Clustered 18 tokens\n",
      "Iteration = 5, Clustered 11 tokens\n",
      "Iteration = 6, Clustered 10 tokens\n",
      "Iteration = 7, Clustered 10 tokens\n",
      "Number of unique installer = 65 after clustering\n"
     ]
    }
   ],
   "source": [
    "funder_similarity_threshold = 0.5\n",
    "installer_similarity_threshold = 0.5\n",
    "\n",
    "for token_column, similarity_threshold in zip(['funder', 'installer'], [funder_similarity_threshold, installer_similarity_threshold]):\n",
    "    print(f'Number of unique {token_column} = {test_samples[token_column].unique().shape[0]} before clustering')\n",
    "\n",
    "    test_samples[token_column] = test_samples[token_column].fillna('unknown')\n",
    "    test_samples[token_column] = test_samples[token_column].replace({'0': 'other', '-1': 'other'})\n",
    "\n",
    "    num_clustered = 1000\n",
    "    num_iteration_clustered = 1\n",
    "    iteration = 0\n",
    "\n",
    "    while num_clustered > 0 and num_clustered != num_iteration_clustered:\n",
    "        num_clustered = num_iteration_clustered\n",
    "\n",
    "        test_samples, num_iteration_clustered = cluster_similar_tokens(\n",
    "            samples_df=test_samples,\n",
    "            preprocessed_token_with_counts=train_inputs[token_column].value_counts(),\n",
    "            target_column=token_column,\n",
    "            similarity_threshold=similarity_threshold\n",
    "        )\n",
    "\n",
    "        iteration += 1\n",
    "        print(f'Iteration = {iteration}, Clustered {num_iteration_clustered} tokens')\n",
    "\n",
    "    for token, count in test_samples[token_column].value_counts().items():\n",
    "        if count < 10:\n",
    "            test_samples.loc[test_samples[token_column] == token, token_column] = 'other'\n",
    "\n",
    "    print(f'Number of unique {token_column} = {test_samples[token_column].unique().shape[0]} after clustering')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imputing Public Meeting & Permit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Public Meeting Imputed: 821\n",
      "Number of Permit Imputed: 737\n"
     ]
    }
   ],
   "source": [
    "test_samples, num_public_meeting_imputed, num_permit_imputed = impute_public_meeting_and_permit(samples_df=test_samples)\n",
    "print(f'Number of Public Meeting Imputed: {num_public_meeting_imputed}')\n",
    "print(f'Number of Permit Imputed: {num_permit_imputed}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scheme Management"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed 364 values of \"scheme_management\" using nearby \"subvillage\" samples\n",
      "Imputed 789 values of \"scheme_management\" using nearby \"ward\" samples\n",
      "NaNs converted to \"Unknown\" = 180\n"
     ]
    }
   ],
   "source": [
    "scheme_management_frequency_threshold = 0.7\n",
    "\n",
    "for location_column in ['subvillage', 'ward']:\n",
    "    nan_ids = np.where(test_samples['scheme_management'].isna())[0]\n",
    "\n",
    "    for nan_ids in nan_ids:\n",
    "        row = test_samples.iloc[nan_ids]\n",
    "\n",
    "        row, imputed = impute_nan_row_by_nearby_samples(\n",
    "            samples_df=train_inputs,\n",
    "            row=row,\n",
    "            location_column=location_column,\n",
    "            target_column='scheme_management',\n",
    "            frequency_threshold=scheme_management_frequency_threshold\n",
    "        )\n",
    "        test_samples.iloc[nan_ids] = row\n",
    "        num_imputed += imputed\n",
    "    print(f'Imputed {num_imputed} values of \"scheme_management\" using nearby \"{location_column}\" samples')\n",
    "\n",
    "num_nans = test_samples['scheme_management'].isna().sum()\n",
    "test_samples['scheme_management'] = test_samples['scheme_management'].fillna('unknown')\n",
    "print(f'NaNs converted to \"Unknown\" = {num_nans}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Management, Payment Type, Water Quality, Quantity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed 789 values of \"management\" using nearby \"ward\" samples\n",
      "Imputed 789 values of \"payment_type\" using nearby \"ward\" samples\n",
      "Imputed 789 values of \"water_quality\" using nearby \"ward\" samples\n",
      "Imputed 789 values of \"quantity\" using nearby \"ward\" samples\n",
      "Imputed 789 values of \"management\" using nearby \"ward\" samples\n",
      "Imputed 789 values of \"payment_type\" using nearby \"ward\" samples\n",
      "Imputed 789 values of \"water_quality\" using nearby \"ward\" samples\n",
      "Imputed 789 values of \"quantity\" using nearby \"ward\" samples\n"
     ]
    }
   ],
   "source": [
    "std_threshold = 0.8\n",
    "\n",
    "for location_col in ['subvillage', 'ward']:\n",
    "    for target_col in ['management', 'payment_type', 'water_quality', 'quantity']:\n",
    "        unknown_ids = np.where(test_samples['scheme_management'].isna())[0]\n",
    "\n",
    "        for unknown_ids in unknown_ids:\n",
    "            row = test_samples.iloc[unknown_ids]\n",
    "\n",
    "            row, imputed = impute_nan_row_by_nearby_samples(\n",
    "                samples_df=train_inputs,\n",
    "                row=row,\n",
    "                location_column=location_col,\n",
    "                target_column=target_col,\n",
    "                frequency_threshold=scheme_management_frequency_threshold\n",
    "            )\n",
    "            test_samples.iloc[unknown_ids] = row\n",
    "            num_imputed += imputed\n",
    "        print(f'Imputed {num_imputed} values of \"{target_col}\" using nearby \"{location_column}\" samples')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Storing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  amount_tsh date_recorded                  funder  gps_height  \\\n0      50785      5500.0    2013-02-04                  w d i       1996.0   \n1      51630         0.0    2013-02-04  government of tanzania      1569.0   \n2      17168         0.0    2013-02-01                 unknown      1567.0   \n3      45559         0.0    2013-01-22       ministry of water       267.0   \n4      49871       500.0    2013-03-27                   redep      1260.0   \n...      ...         ...           ...                     ...         ...   \n14845  39307        50.0    2011-02-24                  danida        34.0   \n14846  18990      1000.0    2011-03-21     the people of japan      1282.0   \n14847  28749         0.0    2013-03-04                 unknown      1476.0   \n14848  33492      2000.0    2013-02-18          oikos e afrika       998.0   \n14849  68707         0.0    2013-02-13  government of tanzania       481.0   \n\n                           installer  longitude   latitude  \\\n0                         tasaf dmdd  35.290799  -4.059696   \n1                                dwe  36.656709  -3.309214   \n2                            unknown  34.767863  -5.004344   \n3                         fini water  38.058046  -9.418672   \n4                              w c s  35.006123 -10.950412   \n...                              ...        ...        ...   \n14845                             da  38.852669  -6.582841   \n14846  halmashauri ya wilaya sikonge  37.451633  -5.350428   \n14847                        unknown  34.739804  -4.585587   \n14848                            dwe  35.432732 -10.584159   \n14849             central government  34.765054 -11.226012   \n\n                      wpt_name  num_private  ... quality_group      quantity  \\\n0      Dinamu Secondary School            0  ...          good      seasonal   \n1                      Kimnyak            0  ...          good  insufficient   \n2               Puma Secondary            0  ...          good  insufficient   \n3               Kwa Mzee Pange            0  ...          good           dry   \n4              Kwa Mzee Turuka            0  ...          good        enough   \n...                        ...          ...  ...           ...           ...   \n14845                Kwambwezi            0  ...          good        enough   \n14846         Bonde La Mkondoa            0  ...         salty  insufficient   \n14847                  Bwawani            0  ...          good  insufficient   \n14848                 Kwa John            0  ...          good  insufficient   \n14849         Kwa Mzee Chagala            0  ...          good           dry   \n\n      quantity_group                source           source_type source_class  \\\n0           seasonal  rainwater harvesting  rainwater harvesting      surface   \n1       insufficient                spring                spring  groundwater   \n2       insufficient  rainwater harvesting  rainwater harvesting      surface   \n3                dry          shallow well          shallow well  groundwater   \n4             enough                spring                spring  groundwater   \n...              ...                   ...                   ...          ...   \n14845         enough                 river            river/lake      surface   \n14846   insufficient          shallow well          shallow well  groundwater   \n14847   insufficient                   dam                   dam      surface   \n14848   insufficient                 river            river/lake      surface   \n14849            dry                spring                spring  groundwater   \n\n          waterpoint_type  waterpoint_type_group seasons operation_time  \n0                   other                  other       0              1  \n1      communal standpipe     communal standpipe       0             13  \n2                   other                  other       0              3  \n3                   other                  other       0             26  \n4      communal standpipe     communal standpipe       1             13  \n...                   ...                    ...     ...            ...  \n14845  communal standpipe     communal standpipe       0             23  \n14846           hand pump              hand pump       1             17  \n14847  communal standpipe     communal standpipe       1              3  \n14848  communal standpipe     communal standpipe       0              4  \n14849  communal standpipe     communal standpipe       0              5  \n\n[14850 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>amount_tsh</th>\n      <th>date_recorded</th>\n      <th>funder</th>\n      <th>gps_height</th>\n      <th>installer</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>wpt_name</th>\n      <th>num_private</th>\n      <th>...</th>\n      <th>quality_group</th>\n      <th>quantity</th>\n      <th>quantity_group</th>\n      <th>source</th>\n      <th>source_type</th>\n      <th>source_class</th>\n      <th>waterpoint_type</th>\n      <th>waterpoint_type_group</th>\n      <th>seasons</th>\n      <th>operation_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50785</td>\n      <td>5500.0</td>\n      <td>2013-02-04</td>\n      <td>w d i</td>\n      <td>1996.0</td>\n      <td>tasaf dmdd</td>\n      <td>35.290799</td>\n      <td>-4.059696</td>\n      <td>Dinamu Secondary School</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>seasonal</td>\n      <td>seasonal</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>other</td>\n      <td>other</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>51630</td>\n      <td>0.0</td>\n      <td>2013-02-04</td>\n      <td>government of tanzania</td>\n      <td>1569.0</td>\n      <td>dwe</td>\n      <td>36.656709</td>\n      <td>-3.309214</td>\n      <td>Kimnyak</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>spring</td>\n      <td>spring</td>\n      <td>groundwater</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>0</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17168</td>\n      <td>0.0</td>\n      <td>2013-02-01</td>\n      <td>unknown</td>\n      <td>1567.0</td>\n      <td>unknown</td>\n      <td>34.767863</td>\n      <td>-5.004344</td>\n      <td>Puma Secondary</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>other</td>\n      <td>other</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>45559</td>\n      <td>0.0</td>\n      <td>2013-01-22</td>\n      <td>ministry of water</td>\n      <td>267.0</td>\n      <td>fini water</td>\n      <td>38.058046</td>\n      <td>-9.418672</td>\n      <td>Kwa Mzee Pange</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>dry</td>\n      <td>dry</td>\n      <td>shallow well</td>\n      <td>shallow well</td>\n      <td>groundwater</td>\n      <td>other</td>\n      <td>other</td>\n      <td>0</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49871</td>\n      <td>500.0</td>\n      <td>2013-03-27</td>\n      <td>redep</td>\n      <td>1260.0</td>\n      <td>w c s</td>\n      <td>35.006123</td>\n      <td>-10.950412</td>\n      <td>Kwa Mzee Turuka</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>spring</td>\n      <td>spring</td>\n      <td>groundwater</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>1</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14845</th>\n      <td>39307</td>\n      <td>50.0</td>\n      <td>2011-02-24</td>\n      <td>danida</td>\n      <td>34.0</td>\n      <td>da</td>\n      <td>38.852669</td>\n      <td>-6.582841</td>\n      <td>Kwambwezi</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>river</td>\n      <td>river/lake</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>0</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>14846</th>\n      <td>18990</td>\n      <td>1000.0</td>\n      <td>2011-03-21</td>\n      <td>the people of japan</td>\n      <td>1282.0</td>\n      <td>halmashauri ya wilaya sikonge</td>\n      <td>37.451633</td>\n      <td>-5.350428</td>\n      <td>Bonde La Mkondoa</td>\n      <td>0</td>\n      <td>...</td>\n      <td>salty</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>shallow well</td>\n      <td>shallow well</td>\n      <td>groundwater</td>\n      <td>hand pump</td>\n      <td>hand pump</td>\n      <td>1</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>14847</th>\n      <td>28749</td>\n      <td>0.0</td>\n      <td>2013-03-04</td>\n      <td>unknown</td>\n      <td>1476.0</td>\n      <td>unknown</td>\n      <td>34.739804</td>\n      <td>-4.585587</td>\n      <td>Bwawani</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>dam</td>\n      <td>dam</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>14848</th>\n      <td>33492</td>\n      <td>2000.0</td>\n      <td>2013-02-18</td>\n      <td>oikos e afrika</td>\n      <td>998.0</td>\n      <td>dwe</td>\n      <td>35.432732</td>\n      <td>-10.584159</td>\n      <td>Kwa John</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>river</td>\n      <td>river/lake</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14849</th>\n      <td>68707</td>\n      <td>0.0</td>\n      <td>2013-02-13</td>\n      <td>government of tanzania</td>\n      <td>481.0</td>\n      <td>central government</td>\n      <td>34.765054</td>\n      <td>-11.226012</td>\n      <td>Kwa Mzee Chagala</td>\n      <td>0</td>\n      <td>...</td>\n      <td>good</td>\n      <td>dry</td>\n      <td>dry</td>\n      <td>spring</td>\n      <td>spring</td>\n      <td>groundwater</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>14850 rows Ã— 42 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples.to_csv('test_inputs.csv', index=False)\n",
    "test_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}